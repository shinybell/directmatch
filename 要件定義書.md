# **エンジニア・研究者ダイレクトリクルーティング MVP 要件定義書**

## **1\. はじめに**

本ドキュメントは、Web 上の公開情報からエンジニアおよび研究者の候補者を見つけ出し、ダイレクトリクルーティングを行うための MVP（Minimum Viable Product）の要件を定義します。

## **2\. 目的**

Web 上の公開情報（GitHub、Qiita、国際学会論文、KAKEN、OpenAlex など）を効率的に収集・分析し、人材要件に合致するエンジニア・研究者を特定するプロセスを最小限の機能で実現することで、ダイレクトリクルーティングの有効性を検証し、今後の本格的なシステム開発の方向性を探る。

## **3\. スコープ**

### **3.1. In-Scope (MVP に含まれる機能)**

- 特定の公開 Web サイト/API からの情報収集
- 収集した情報のデータベースへの保存
- 簡易的な同一人物の特定と情報の統合
- 人材要件（テキスト入力）に基づく NLP による適合度計算
- 適合度スコアに基づく候補者リストの表示と簡易検索
- 候補者の公開連絡先（メールアドレス、SNS リンクなど）の閲覧・コピー
- 小規模データ（数百〜数千件）での動作

### **3.2. Out-of-Scope (MVP には含まれない機能)**

- 自動スカウトメール送信機能
- 候補者とのコミュニケーション管理（CRM 機能）
- 高度な同一人物特定（機械学習による名寄せなど）
- リアルタイムデータ同期
- ユーザー認証・権限管理
- 大規模データ（数万件以上）の処理
- 履歴書/職務経歴書自動パース機能
- Web サイトへの無許可スクレイピング（API 利用が主）

## **4\. ターゲットユーザー**

- 採用担当者
- 各ポジションのリードエンジニア、研究者（採用協力者）

## **5\. 機能要件**

### **5.1. データ収集機能**

- **R001**: 以下の API を利用して情報を取得できること。
  - 研究者向け: OpenAlex API, KAKEN API (必要に応じて ICLR などの国際学会サイトからの情報抽出も検討)
    - **OpenAlex**: /authors および /works エンドポイントを利用し、著者情報（氏名、ORCID ID、所属、論文リスト）および論文詳細（タイトル、アブストラクト、キーワード、被引用数）を取得。
    - **KAKEN**: 研究者情報、研究課題情報を取得。
  - エンジニア向け: GitHub API, Qiita API
    - **GitHub**: /users (ユーザープロフィール), /repos (リポジトリ詳細), /search/code (コード検索) エンドポイントを利用し、ユーザー名、プロフィール（自己紹介文、所属）、主要リポジトリ（名称、README、主要言語、スター数、最終コミット日）を取得。
    - **Qiita**: /users (ユーザー情報), /items (記事情報) エンドポイントを利用し、ユーザー ID、記事タイトル、本文、タグ、いいね数などを取得。
- **R002**: 各 API のレートリミットを考慮し、適切な間隔でリクエストを行うこと。エラー発生時にはリトライ機構を実装すること。
- **R003**: 取得する情報は、後述のデータモデルに合わせて抽出・整形できること。

### **5.2. データ保存と管理機能**

- **R004**: 収集したデータを SQLite データベースに保存できること。
- **R005**: 以下のデータモデルに基づき、情報を構造化して格納できること。
  - persons テーブルに、各情報源から抽出した「経験」をまとめたテキストデータ（experience_summary カラム）を格納できること。
    - experience_summary は、GitHub の README、主要リポジトリの説明、Qiita の記事本文、論文のアブストラクト、KAKEN の研究概要などを結合・要約して生成すること。
  - 各情報源からの生のデータ（JSON など）も必要に応じて保持できること。

### **5.3. 同一人物特定と統合機能**

- **R006**: 複数の情報源から取得したデータについて、以下の優先順位で同一人物を特定し、persons テーブルに情報を統合できること。
  1. 公開されているメールアドレスの一致
  2. ORCID ID（研究者）の一致
  3. GitHub ユーザー名の一致
  4. 氏名と現所属機関の完全一致 (厳密な文字列比較)
- **R007**: 統合されたデータは、個人の最新の情報となるように更新できること。

### **5.4. 人材要件マッチング機能**

- **R008**: ユーザーが Web UI 上から、募集するポジションの人材要件をテキスト形式で入力できるフォームを提供すること（例: Streamlit の st.text_area ウィジェット）。
  - 例: 「機械学習を使った 5 年以上の実務経験」「自己教師あり学習の実装経験」「Python、TensorFlow、PyTorch の習熟度」「ICLR での発表経験」など。
- **R009**: 入力された人材要件テキストと、各候補者の experience_summary カラムに格納されたテキストとの間で、NLP（TF-IDF \+ コサイン類似度）を用いて適合度スコアを計算できること。
  - **日本語前処理**: MeCab（または fugashi \+ ipadic）を用いて形態素解析を行い、名詞、動詞の原型、形容詞などを抽出すること。一般的なストップワード（例: 「です」「ます」「こと」「もの」など）は除去すること。
  - **英語前処理**: nltk などを用いてトークン化、小文字化、ストップワード除去、ステミング/レンマ化を行うこと。
- **R010**: 計算された適合度スコアを候補者ごとに表示できること。

### **5.5. ユーザーインターフェース (UI) 機能**

- **R011**: Streamlit フレームワークを使用して Web UI を構築すること。
- **R012**: 適合度スコアの高い順に並べ替え可能な候補者リストをテーブル形式で表示できること（例: st.dataframe ウィジェット）。表示項目は氏名、所属、適合度スコア、主要な公開プロフィール URL（GitHub, Qiita, 論文）とすること。
- **R013**: 氏名やキーワード（例: experience_summary 内の単語）で候補者を検索・フィルタリングできる検索バーを提供すること（例: st.text_input ウィジェット）。
- **R014**: 各候補者の詳細画面（または簡易モーダル）で、取得した全情報と公開連絡先（メールアドレス、SNS リンクなど）を表示できること。
- **R015**: 候補者の公開連絡先を簡単にコピーできるボタンまたは機能を提供すること。

## **6\. 非機能要件**

- **パフォーマンス**: 数百〜数千件の候補者データが登録された状態で、検索・ソート処理が数秒以内に完了すること。
- **セキュリティ**: 収集した個人情報へのアクセスは、システム管理者のみに制限されること。データベースへの接続情報や API キーなどの機密情報は、.env ファイルなどの環境変数で管理し、コードに直接ハードコードしないこと。
- **可用性**: シンプルな単一サーバーでの運用を前提とする。
- **拡張性**: 将来的な機能追加（例: より高度な NLP モデル、データソースの追加）を考慮した、モジュール化されたコード設計を心がけること。
- **運用性**: エラー発生時に適切なログが出力されること。ログレベル（DEBUG, INFO, WARNING, ERROR）を設定し、特に API エラー、DB エラー、NLP 処理エラーは ERROR レベルで記録すること。

## **7\. システムアーキテクチャ（小規模開発向け）**

本 MVP では、開発の容易性と迅速なプロトタイピングを重視したシンプルかつ統合的なアーキテクチャを採用します。

```
\+----------------+       \+-------------------+       \+--------------------+
|                |       |                   |       |                    |
|  データソース  |\<-----\>|  データ収集スクリプト   |\<-----\>|                    |
| (GitHub API,   |       | (Python: requests)|       |  SQLite            |
|  Qiita API,    |       |                   |       |   (データストア)   |
|  OpenAlex API,)|       \+-------------------+       |                    |
|  KAKEN API)    |                                   \+----------^---------+
|                |                                              |
\+----------------+                                              |
                                                                |
                                                                |
\+-----------------------+      \+--------------------------+     |
|                       |      |                          |     |
|  Web UI (Streamlit)   |\<----\>|   バックエンドロジック   |-----+
|  (候補者表示, 検索,    |      |  (Python: pandas, numpy, |
|   要件入力)            |      |  scikit-learn, (gensim)) |
|                       |      |  \- 同一人物特定          |
|                       |      |  \- NLPマッチング         |
\+-----------------------+      |  \- DB操作                |
                               \+--------------------------+
```

### **7.1. 技術スタック**

- **プログラミング言語**: Python 3.9+
- **Web フレームワーク**: Streamlit (UI & バックエンドロジック)
- **データ収集**: requests
- **データベース**: SQLite (MVP 向け)
- **データベース ORM**: SQLAlchemy (または直接 sqlite3 での操作)
- **データ処理・分析**: pandas, numpy
- **NLP**: scikit-learn (TF-IDF, Cosine Similarity), nltk / MeCab (日本語前処理)
  - 日本語の前処理のため、MeCab や fugashi \+ ipadic の利用を検討すること。

### **7.2. データフロー**

1. **データ収集スクリプト**: 各 API を叩き、JSON 形式で生データを取得。
2. **データ前処理**: 生データから、persons テーブルに必要なカラム（特に experience_summary）を抽出・整形。
3. **データ保存**: データベースにデータを挿入または更新。同一人物判定ロジックを適用。
   - **初期データ投入**: データベースを初期化し、少量のサンプルデータを収集して投入するための独立したスクリプト（例: populate_db.py）を準備すること。これにより、開発・テストが容易になる。
4. **Web UI (Streamlit)**:
   - ユーザーが人材要件を入力。
   - 入力された要件とデータベース内の experience_summary カラムを NLP で比較し、適合度を計算。
   - 結果を UI に表示。ユーザーは候補者リストを閲覧、検索、ソート、詳細確認が可能。
   - 公開連絡先のコピー操作。

## **8\. データモデル（MVP 版）**

### **persons テーブル**

| カラム名               | 型        | 制約             | 説明                                            |
| :--------------------- | :-------- | :--------------- | :---------------------------------------------- |
| id                     | UUID/TEXT | PRIMARY KEY      | 内部で生成されるユニークな人物 ID               |
| full_name              | TEXT      | NOT NULL         | 氏名                                            |
| email                  | TEXT      | NULLABLE         | メールアドレス（公開されている場合）            |
| current_affiliation    | TEXT      | NULLABLE         | 現在の所属機関                                  |
| github_username        | TEXT      | UNIQUE, NULLABLE | GitHub ユーザー名                               |
| qiita_id               | TEXT      | UNIQUE, NULLABLE | Qiita ユーザー ID                               |
| orcid_id               | TEXT      | UNIQUE, NULLABLE | ORCID ID（研究者向け）                          |
| linkedin_url           | TEXT      | NULLABLE         | LinkedIn 公開プロフィール URL                   |
| personal_blog_url      | TEXT      | NULLABLE         | 個人ブログ URL                                  |
| is_researcher          | BOOLEAN   | NOT NULL         | 研究者フラグ（true/false）                      |
| is_engineer            | BOOLEAN   | NOT NULL         | エンジニアフラグ（true/false）                  |
| **experience_summary** | TEXT      | NULLABLE         | GitHub, Qiita, 論文などから抽出した経験サマリ   |
| raw_github_data        | JSONB     | NULLABLE         | GitHub API から取得した生データ（JSON）         |
| raw_qiita_data         | JSONB     | NULLABLE         | Qiita API から取得した生データ（JSON）          |
| raw_openalex_data      | JSONB     | NULLABLE         | OpenAlex から取得した論文の主要生データ（JSON） |
| raw_kaken_data         | JSONB     | NULLABLE         | KAKEN から取得した研究課題生データ（JSON）      |
| last_updated_at        | TIMESTAMP | NOT NULL         | 最終更新日時                                    |
| match_score            | REAL      | NULLABLE         | 現在の人材要件との適合度スコア（UI 表示用）     |

## **9\. 留意事項**

- **個人情報保護法**: Web 上の公開情報であっても、収集・利用には個人情報保護法が適用されます。MVP 段階から、利用目的の明確な公表（プライバシーポリシーへの記載）、本人からの削除・停止要求への対応方法の確立、適切なデータ管理とセキュリティ対策を意識すること。
- **各 API/サイトの利用規約**: GitHub, Qiita, OpenAlex, KAKEN などの API や Web サイトの利用規約を厳守すること。特に商用利用や大規模なデータ収集に関する制限を確認すること。無許可の Web スクレイピングは行わないこと。
- **データ品質と NLP**: 収集されるテキストデータにはノイズが含まれる可能性があるため、NLP の前処理（例: 日本語の形態素解析）の精度がマッチング結果に大きく影響します。
- **同一人物特定**: MVP 段階の簡易的な特定ロジックでは、誤った統合や同一人物の見逃しが発生する可能性があります。これは後のフェーズで改善するスコープとする。
- **フィードバックループ**: MVP を実際に利用し、採用担当者からのフィードバックを積極的に収集し、次の開発イテレーションに活かすこと。

## **10\. ディレクトリ構成**

本プロジェクトの推奨ディレクトリ構成は以下の通りです。

```
project\_root/
├── app.py                      \# Streamlitアプリケーションのエントリーポイント（UIと上位のロジックを記述）
├── config.py                   \# アプリケーション共通の設定（APIキー、DBパスなど）
├── requirements.txt            \# Pythonの依存関係リスト
├── .env                        \# 環境変数（APIキーなどの機密情報）
├── data/                       \# データ保存用ディレクトリ
│   └── recruiting\_mvp.db       \# SQLiteデータベースファイル
└── src/                        \# アプリケーションのコアロジックを格納
    ├── \_\_init\_\_.py             \# Pythonパッケージとして認識させるためのファイル
    ├── data\_collection/        \# 外部APIとの連携、データ取得ロジック
    │   ├── \_\_init\_\_.py
    │   ├── github\_client.py    \# GitHub APIクライアント
    │   ├── qiita\_client.py     \# Qiita APIクライアント
    │   ├── openalex\_client.py  \# OpenAlex APIクライアント
    │   ├── kaken\_client.py     \# KAKEN APIクライアント
    │   └── collector.py        \# 各クライアントを呼び出し、データ収集を統括するモジュール
    ├── database/               \# データベース操作関連ロジック
    │   ├── \_\_init\_\_.py
    │   ├── models.py           \# SQLAlchemy ORMモデル定義（personsテーブルなど）
    │   ├── db\_manager.py       \# データベース接続、セッション管理
    │   └── crud.py             \# CRUD操作（データの作成、読み込み、更新、削除）
    ├── nlp\_processing/         \# 自然言語処理関連ロジック
    │   ├── \_\_init\_\_.py
    │   ├── preprocessor.py     \# テキスト前処理（トークン化、正規化、日本語処理など）
    │   ├── matcher.py          \# TF-IDFベクトル化とコサイン類似度計算
    │   └── models.py           \# NLPモデル（TF-IDF Vectorizerなど）のロード/保存
    ├── core/                   \# アプリケーションの主要ビジネスロジック（サービスレイヤー）
    │   ├── \_\_init\_\_.py
    │   └── recruitment\_service.py \# データ収集、NLP処理、データベース操作を連携させ、採用活動の主要ロジックを実装
    └── utils/                  \# 汎用的なユーティリティ関数
        ├── \_\_init\_\_.py
        └── common.py           \# ID生成、エラーハンドリングなど、共通で利用する関数
```
